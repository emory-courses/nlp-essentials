"use strict";(globalThis.webpackChunknlp_essentials_textbook=globalThis.webpackChunknlp_essentials_textbook||[]).push([[9015],{285(e,s,a){a.r(s),a.d(s,{assets:()=>h,contentTitle:()=>r,default:()=>o,frontMatter:()=>l,metadata:()=>n,toc:()=>c});const n=JSON.parse('{"id":"chapters/language_models/homework","title":"Homework","description":"HW2: Language Models","source":"@site/docs/chapters/language_models/homework.md","sourceDirName":"chapters/language_models","slug":"/chapters/language_models/homework","permalink":"/nlp-essentials/chapters/language_models/homework","draft":false,"unlisted":false,"editUrl":"https://github.com/emory-courses/nlp-essentials/tree/main/docs/chapters/language_models/homework.md","tags":[],"version":"current","frontMatter":{"title":"Homework","description":"HW2: Language Models"},"sidebar":"chaptersSidebar","previous":{"title":"Entropy and Perplexity","permalink":"/nlp-essentials/chapters/language_models/entropy-and-perplexity"},"next":{"title":"Overview","permalink":"/nlp-essentials/chapters/large_language_models/overview"}}');var i=a(4848),t=a(8453);const l={title:"Homework",description:"HW2: Language Models"},r="Homework",h={},c=[{value:"Task 1: Bigram Modeling",id:"task-1-bigram-modeling",level:2},{value:"Implementation",id:"implementation",level:3},{value:"Notes",id:"notes",level:3},{value:"Task 2: Sequence Generation",id:"task-2-sequence-generation",level:2},{value:"Implementation",id:"implementation-1",level:3},{value:"Extra Credit",id:"extra-credit",level:3},{value:"Submission",id:"submission",level:2},{value:"Rubric",id:"rubric",level:2}];function m(e){const s={a:"a",annotation:"annotation",code:"code",h1:"h1",h2:"h2",h3:"h3",header:"header",li:"li",math:"math",mi:"mi",mn:"mn",mo:"mo",mrow:"mrow",msub:"msub",msup:"msup",mtext:"mtext",ol:"ol",p:"p",pre:"pre",semantics:"semantics",span:"span",strong:"strong",ul:"ul",...(0,t.R)(),...e.components};return(0,i.jsxs)(i.Fragment,{children:[(0,i.jsx)(s.header,{children:(0,i.jsx)(s.h1,{id:"homework",children:"Homework"})}),"\n",(0,i.jsx)(s.h2,{id:"task-1-bigram-modeling",children:"Task 1: Bigram Modeling"}),"\n",(0,i.jsxs)(s.p,{children:["Your goal is to build a bigram model using (1) Laplace smoothing with ",(0,i.jsx)(s.a,{href:"/nlp-essentials/chapters/language_models/smoothing#normalization",children:"normalization"})," and (2) ",(0,i.jsx)(s.a,{href:"/nlp-essentials/chapters/language_models/maximum-likelihood-estimation#initial-word-probability",children:"initial word probabilities"})," by adding the artificial token ",(0,i.jsxs)(s.span,{className:"katex",children:[(0,i.jsx)(s.span,{className:"katex-mathml",children:(0,i.jsx)(s.math,{xmlns:"http://www.w3.org/1998/Math/MathML",children:(0,i.jsxs)(s.semantics,{children:[(0,i.jsx)(s.mrow,{children:(0,i.jsxs)(s.msub,{children:[(0,i.jsx)(s.mi,{children:"w"}),(0,i.jsx)(s.mn,{children:"0"})]})}),(0,i.jsx)(s.annotation,{encoding:"application/x-tex",children:"w_0"})]})})}),(0,i.jsx)(s.span,{className:"katex-html","aria-hidden":"true",children:(0,i.jsxs)(s.span,{className:"base",children:[(0,i.jsx)(s.span,{className:"strut",style:{height:"0.5806em",verticalAlign:"-0.15em"}}),(0,i.jsxs)(s.span,{className:"mord",children:[(0,i.jsx)(s.span,{className:"mord mathnormal",style:{marginRight:"0.02691em"},children:"w"}),(0,i.jsx)(s.span,{className:"msupsub",children:(0,i.jsxs)(s.span,{className:"vlist-t vlist-t2",children:[(0,i.jsxs)(s.span,{className:"vlist-r",children:[(0,i.jsx)(s.span,{className:"vlist",style:{height:"0.3011em"},children:(0,i.jsxs)(s.span,{style:{top:"-2.55em",marginLeft:"-0.0269em",marginRight:"0.05em"},children:[(0,i.jsx)(s.span,{className:"pstrut",style:{height:"2.7em"}}),(0,i.jsx)(s.span,{className:"sizing reset-size6 size3 mtight",children:(0,i.jsx)(s.span,{className:"mord mtight",children:"0"})})]})}),(0,i.jsx)(s.span,{className:"vlist-s",children:"\u200b"})]}),(0,i.jsx)(s.span,{className:"vlist-r",children:(0,i.jsx)(s.span,{className:"vlist",style:{height:"0.15em"},children:(0,i.jsx)(s.span,{})})})]})})]})]})})]})," at the beginning of every sentence."]}),"\n",(0,i.jsx)(s.h3,{id:"implementation",children:"Implementation"}),"\n",(0,i.jsxs)(s.ol,{children:["\n",(0,i.jsxs)(s.li,{children:["Create a ",(0,i.jsx)(s.a,{href:"https://github.com/emory-courses/nlp-essentials/blob/main/src/homework/language_models.py",children:(0,i.jsx)(s.strong,{children:"language_models.py"})})," file in the ",(0,i.jsx)(s.a,{href:"https://github.com/emory-courses/nlp-essentials/tree/main/src/homework",children:"src/homework/"})," directory."]}),"\n",(0,i.jsxs)(s.li,{children:["Define a function named ",(0,i.jsx)(s.code,{children:"bigram_model()"})," that takes a file path pointing to the text file, and returns a dictionary of bigram probabilities estimated in the text file."]}),"\n",(0,i.jsx)(s.li,{children:"Use the following constants to indicate the unknown and initial probabilities:"}),"\n"]}),"\n",(0,i.jsx)(s.pre,{children:(0,i.jsx)(s.code,{className:"language-python",children:"UNKNOWN = ''\nINIT = '[INIT]'\n"})}),"\n",(0,i.jsx)(s.h3,{id:"notes",children:"Notes"}),"\n",(0,i.jsxs)(s.ol,{children:["\n",(0,i.jsxs)(s.li,{children:["Test your model using ",(0,i.jsx)(s.a,{href:"https://github.com/emory-courses/nlp-essentials/blob/main/dat/chronicles_of_narnia.txt",children:"dat/chronicles_of_narnia.txt"}),"."]}),"\n",(0,i.jsxs)(s.li,{children:["Each line should be treated independently for bigram counting such that the ",(0,i.jsx)(s.code,{children:"INIT"})," token should precede the first word of each line."]}),"\n",(0,i.jsxs)(s.li,{children:["Use ",(0,i.jsx)(s.a,{href:"/nlp-essentials/chapters/language_models/smoothing#normalization",children:"smoothing with normalization"})," such that all probabilities must sum to 1.0 for any given previous word."]}),"\n",(0,i.jsxs)(s.li,{children:["Unknown word probabilities should be retrieved using the ",(0,i.jsx)(s.code,{children:"UNKNOWN"})," key for both the previous word (",(0,i.jsxs)(s.span,{className:"katex",children:[(0,i.jsx)(s.span,{className:"katex-mathml",children:(0,i.jsx)(s.math,{xmlns:"http://www.w3.org/1998/Math/MathML",children:(0,i.jsxs)(s.semantics,{children:[(0,i.jsx)(s.mrow,{children:(0,i.jsxs)(s.msub,{children:[(0,i.jsx)(s.mi,{children:"w"}),(0,i.jsxs)(s.mrow,{children:[(0,i.jsx)(s.mi,{children:"i"}),(0,i.jsx)(s.mo,{children:"\u2212"}),(0,i.jsx)(s.mn,{children:"1"})]})]})}),(0,i.jsx)(s.annotation,{encoding:"application/x-tex",children:"w_{i-1}"})]})})}),(0,i.jsx)(s.span,{className:"katex-html","aria-hidden":"true",children:(0,i.jsxs)(s.span,{className:"base",children:[(0,i.jsx)(s.span,{className:"strut",style:{height:"0.6389em",verticalAlign:"-0.2083em"}}),(0,i.jsxs)(s.span,{className:"mord",children:[(0,i.jsx)(s.span,{className:"mord mathnormal",style:{marginRight:"0.02691em"},children:"w"}),(0,i.jsx)(s.span,{className:"msupsub",children:(0,i.jsxs)(s.span,{className:"vlist-t vlist-t2",children:[(0,i.jsxs)(s.span,{className:"vlist-r",children:[(0,i.jsx)(s.span,{className:"vlist",style:{height:"0.3117em"},children:(0,i.jsxs)(s.span,{style:{top:"-2.55em",marginLeft:"-0.0269em",marginRight:"0.05em"},children:[(0,i.jsx)(s.span,{className:"pstrut",style:{height:"2.7em"}}),(0,i.jsx)(s.span,{className:"sizing reset-size6 size3 mtight",children:(0,i.jsxs)(s.span,{className:"mord mtight",children:[(0,i.jsx)(s.span,{className:"mord mathnormal mtight",children:"i"}),(0,i.jsx)(s.span,{className:"mbin mtight",children:"\u2212"}),(0,i.jsx)(s.span,{className:"mord mtight",children:"1"})]})})]})}),(0,i.jsx)(s.span,{className:"vlist-s",children:"\u200b"})]}),(0,i.jsx)(s.span,{className:"vlist-r",children:(0,i.jsx)(s.span,{className:"vlist",style:{height:"0.2083em"},children:(0,i.jsx)(s.span,{})})})]})})]})]})})]}),") and the current word (",(0,i.jsxs)(s.span,{className:"katex",children:[(0,i.jsx)(s.span,{className:"katex-mathml",children:(0,i.jsx)(s.math,{xmlns:"http://www.w3.org/1998/Math/MathML",children:(0,i.jsxs)(s.semantics,{children:[(0,i.jsx)(s.mrow,{children:(0,i.jsxs)(s.msub,{children:[(0,i.jsx)(s.mi,{children:"w"}),(0,i.jsx)(s.mi,{children:"i"})]})}),(0,i.jsx)(s.annotation,{encoding:"application/x-tex",children:"w_i"})]})})}),(0,i.jsx)(s.span,{className:"katex-html","aria-hidden":"true",children:(0,i.jsxs)(s.span,{className:"base",children:[(0,i.jsx)(s.span,{className:"strut",style:{height:"0.5806em",verticalAlign:"-0.15em"}}),(0,i.jsxs)(s.span,{className:"mord",children:[(0,i.jsx)(s.span,{className:"mord mathnormal",style:{marginRight:"0.02691em"},children:"w"}),(0,i.jsx)(s.span,{className:"msupsub",children:(0,i.jsxs)(s.span,{className:"vlist-t vlist-t2",children:[(0,i.jsxs)(s.span,{className:"vlist-r",children:[(0,i.jsx)(s.span,{className:"vlist",style:{height:"0.3117em"},children:(0,i.jsxs)(s.span,{style:{top:"-2.55em",marginLeft:"-0.0269em",marginRight:"0.05em"},children:[(0,i.jsx)(s.span,{className:"pstrut",style:{height:"2.7em"}}),(0,i.jsx)(s.span,{className:"sizing reset-size6 size3 mtight",children:(0,i.jsx)(s.span,{className:"mord mathnormal mtight",children:"i"})})]})}),(0,i.jsx)(s.span,{className:"vlist-s",children:"\u200b"})]}),(0,i.jsx)(s.span,{className:"vlist-r",children:(0,i.jsx)(s.span,{className:"vlist",style:{height:"0.15em"},children:(0,i.jsx)(s.span,{})})})]})})]})]})})]}),")."]}),"\n"]}),"\n",(0,i.jsx)(s.h2,{id:"task-2-sequence-generation",children:"Task 2: Sequence Generation"}),"\n",(0,i.jsx)(s.p,{children:"Your goal is to write a function that takes a word and generates a sequence that includes the input as the initial word."}),"\n",(0,i.jsx)(s.h3,{id:"implementation-1",children:"Implementation"}),"\n",(0,i.jsxs)(s.p,{children:["Under ",(0,i.jsx)(s.a,{href:"https://github.com/emory-courses/nlp-essentials/blob/main/src/homework/language_models.py",children:(0,i.jsx)(s.strong,{children:"language_models.py"})}),", define a function named ",(0,i.jsx)(s.code,{children:"sequence_generator()"})," that takes the following parameters:"]}),"\n",(0,i.jsxs)(s.ul,{children:["\n",(0,i.jsx)(s.li,{children:"A bigram model (the resulting dictionary of Task 1)"}),"\n",(0,i.jsx)(s.li,{children:"The initial word (the first word to appear in the sequence)"}),"\n",(0,i.jsx)(s.li,{children:"The length of the sequence (the number of tokens in the sequence)"}),"\n"]}),"\n",(0,i.jsx)(s.p,{children:"This function aims to generate a sequence of tokens that adheres to the following criteria:"}),"\n",(0,i.jsxs)(s.ul,{children:["\n",(0,i.jsx)(s.li,{children:"It must have the precise number of tokens as specified."}),"\n",(0,i.jsxs)(s.li,{children:["Not more than 20% of the tokens can be punctuation. For instance, if the sequence length is 20, a maximum of 4 punctuation tokens are permitted within the sequence. Use floor of 20% (e.g., if the sequence length is 21, a maximum of ",(0,i.jsxs)(s.span,{className:"katex",children:[(0,i.jsx)(s.span,{className:"katex-mathml",children:(0,i.jsx)(s.math,{xmlns:"http://www.w3.org/1998/Math/MathML",children:(0,i.jsxs)(s.semantics,{children:[(0,i.jsxs)(s.mrow,{children:[(0,i.jsxs)(s.mrow,{children:[(0,i.jsx)(s.mi,{mathvariant:"normal",children:"f"}),(0,i.jsx)(s.mi,{mathvariant:"normal",children:"l"}),(0,i.jsx)(s.mi,{mathvariant:"normal",children:"o"}),(0,i.jsx)(s.mi,{mathvariant:"normal",children:"o"}),(0,i.jsx)(s.mi,{mathvariant:"normal",children:"r"})]}),(0,i.jsx)(s.mo,{stretchy:"false",children:"("}),(0,i.jsx)(s.mn,{children:"21"}),(0,i.jsx)(s.mi,{mathvariant:"normal",children:"/"}),(0,i.jsx)(s.mn,{children:"5"}),(0,i.jsx)(s.mo,{stretchy:"false",children:")"}),(0,i.jsx)(s.mo,{children:"="}),(0,i.jsx)(s.mn,{children:"4"})]}),(0,i.jsx)(s.annotation,{encoding:"application/x-tex",children:"\\mathrm{floor}(21 / 5) = 4"})]})})}),(0,i.jsxs)(s.span,{className:"katex-html","aria-hidden":"true",children:[(0,i.jsxs)(s.span,{className:"base",children:[(0,i.jsx)(s.span,{className:"strut",style:{height:"1em",verticalAlign:"-0.25em"}}),(0,i.jsx)(s.span,{className:"mord",children:(0,i.jsx)(s.span,{className:"mord mathrm",children:"floor"})}),(0,i.jsx)(s.span,{className:"mopen",children:"("}),(0,i.jsx)(s.span,{className:"mord",children:"21/5"}),(0,i.jsx)(s.span,{className:"mclose",children:")"}),(0,i.jsx)(s.span,{className:"mspace",style:{marginRight:"0.2778em"}}),(0,i.jsx)(s.span,{className:"mrel",children:"="}),(0,i.jsx)(s.span,{className:"mspace",style:{marginRight:"0.2778em"}})]}),(0,i.jsxs)(s.span,{className:"base",children:[(0,i.jsx)(s.span,{className:"strut",style:{height:"0.6444em"}}),(0,i.jsx)(s.span,{className:"mord",children:"4"})]})]})]})," puncuation tokens are permitted)."]}),"\n",(0,i.jsx)(s.li,{children:"Excluding punctuation, there should be no redundant tokens in the sequence."}),"\n"]}),"\n",(0,i.jsxs)(s.p,{children:["The goal of this task is not to discover a sequence that maximizes the overall ",(0,i.jsx)(s.a,{href:"/nlp-essentials/chapters/language_models/maximum-likelihood-estimation#sequence-probability",children:"sequence probability"}),", but rather to optimize individual bigram probabilities. Hence, it entails a greedy search approach rather than an exhaustive one. Given the input word ",(0,i.jsxs)(s.span,{className:"katex",children:[(0,i.jsx)(s.span,{className:"katex-mathml",children:(0,i.jsx)(s.math,{xmlns:"http://www.w3.org/1998/Math/MathML",children:(0,i.jsxs)(s.semantics,{children:[(0,i.jsx)(s.mrow,{children:(0,i.jsx)(s.mi,{children:"w"})}),(0,i.jsx)(s.annotation,{encoding:"application/x-tex",children:"w"})]})})}),(0,i.jsx)(s.span,{className:"katex-html","aria-hidden":"true",children:(0,i.jsxs)(s.span,{className:"base",children:[(0,i.jsx)(s.span,{className:"strut",style:{height:"0.4306em"}}),(0,i.jsx)(s.span,{className:"mord mathnormal",style:{marginRight:"0.02691em"},children:"w"})]})})]}),", a potential strategy is as follows:"]}),"\n",(0,i.jsxs)(s.ol,{children:["\n",(0,i.jsxs)(s.li,{children:["Identify the next word ",(0,i.jsxs)(s.span,{className:"katex",children:[(0,i.jsx)(s.span,{className:"katex-mathml",children:(0,i.jsx)(s.math,{xmlns:"http://www.w3.org/1998/Math/MathML",children:(0,i.jsxs)(s.semantics,{children:[(0,i.jsx)(s.mrow,{children:(0,i.jsxs)(s.msup,{children:[(0,i.jsx)(s.mi,{children:"w"}),(0,i.jsx)(s.mo,{mathvariant:"normal",lspace:"0em",rspace:"0em",children:"\u2032"})]})}),(0,i.jsx)(s.annotation,{encoding:"application/x-tex",children:"w'"})]})})}),(0,i.jsx)(s.span,{className:"katex-html","aria-hidden":"true",children:(0,i.jsxs)(s.span,{className:"base",children:[(0,i.jsx)(s.span,{className:"strut",style:{height:"0.7519em"}}),(0,i.jsxs)(s.span,{className:"mord",children:[(0,i.jsx)(s.span,{className:"mord mathnormal",style:{marginRight:"0.02691em"},children:"w"}),(0,i.jsx)(s.span,{className:"msupsub",children:(0,i.jsx)(s.span,{className:"vlist-t",children:(0,i.jsx)(s.span,{className:"vlist-r",children:(0,i.jsx)(s.span,{className:"vlist",style:{height:"0.7519em"},children:(0,i.jsxs)(s.span,{style:{top:"-3.063em",marginRight:"0.05em"},children:[(0,i.jsx)(s.span,{className:"pstrut",style:{height:"2.7em"}}),(0,i.jsx)(s.span,{className:"sizing reset-size6 size3 mtight",children:(0,i.jsx)(s.span,{className:"mord mtight",children:(0,i.jsx)(s.span,{className:"mord mtight",children:"\u2032"})})})]})})})})})]})]})})]})," where the bigram probability ",(0,i.jsxs)(s.span,{className:"katex",children:[(0,i.jsx)(s.span,{className:"katex-mathml",children:(0,i.jsx)(s.math,{xmlns:"http://www.w3.org/1998/Math/MathML",children:(0,i.jsxs)(s.semantics,{children:[(0,i.jsxs)(s.mrow,{children:[(0,i.jsx)(s.mi,{children:"P"}),(0,i.jsx)(s.mo,{stretchy:"false",children:"("}),(0,i.jsx)(s.mi,{children:"w"}),(0,i.jsx)(s.mtext,{children:"\u2032"}),(0,i.jsx)(s.mo,{children:"\u2223"}),(0,i.jsx)(s.mi,{children:"w"}),(0,i.jsx)(s.mo,{stretchy:"false",children:")"})]}),(0,i.jsx)(s.annotation,{encoding:"application/x-tex",children:"P(w\u2032\u2223w)"})]})})}),(0,i.jsxs)(s.span,{className:"katex-html","aria-hidden":"true",children:[(0,i.jsxs)(s.span,{className:"base",children:[(0,i.jsx)(s.span,{className:"strut",style:{height:"1em",verticalAlign:"-0.25em"}}),(0,i.jsx)(s.span,{className:"mord mathnormal",style:{marginRight:"0.13889em"},children:"P"}),(0,i.jsx)(s.span,{className:"mopen",children:"("}),(0,i.jsx)(s.span,{className:"mord mathnormal",style:{marginRight:"0.02691em"},children:"w"}),(0,i.jsx)(s.span,{className:"mord",children:"\u2032"}),(0,i.jsx)(s.span,{className:"mspace",style:{marginRight:"0.2778em"}}),(0,i.jsx)(s.span,{className:"mrel",children:"\u2223"}),(0,i.jsx)(s.span,{className:"mspace",style:{marginRight:"0.2778em"}})]}),(0,i.jsxs)(s.span,{className:"base",children:[(0,i.jsx)(s.span,{className:"strut",style:{height:"1em",verticalAlign:"-0.25em"}}),(0,i.jsx)(s.span,{className:"mord mathnormal",style:{marginRight:"0.02691em"},children:"w"}),(0,i.jsx)(s.span,{className:"mclose",children:")"})]})]})]})," is maximized."]}),"\n",(0,i.jsxs)(s.li,{children:["If ",(0,i.jsxs)(s.span,{className:"katex",children:[(0,i.jsx)(s.span,{className:"katex-mathml",children:(0,i.jsx)(s.math,{xmlns:"http://www.w3.org/1998/Math/MathML",children:(0,i.jsxs)(s.semantics,{children:[(0,i.jsxs)(s.mrow,{children:[(0,i.jsx)(s.mi,{children:"w"}),(0,i.jsx)(s.mtext,{children:"\u2032"})]}),(0,i.jsx)(s.annotation,{encoding:"application/x-tex",children:"w\u2032"})]})})}),(0,i.jsx)(s.span,{className:"katex-html","aria-hidden":"true",children:(0,i.jsxs)(s.span,{className:"base",children:[(0,i.jsx)(s.span,{className:"strut",style:{height:"0.5556em"}}),(0,i.jsx)(s.span,{className:"mord mathnormal",style:{marginRight:"0.02691em"},children:"w"}),(0,i.jsx)(s.span,{className:"mord",children:"\u2032"})]})})]})," fulfills all the stipulated conditions, include it in the sequence and proceed. Otherwise, search for the next word whose bigram probability is the second highest. Repeat this process until you encounter a word that meets all the specified conditions."]}),"\n",(0,i.jsxs)(s.li,{children:["Make ",(0,i.jsxs)(s.span,{className:"katex",children:[(0,i.jsx)(s.span,{className:"katex-mathml",children:(0,i.jsx)(s.math,{xmlns:"http://www.w3.org/1998/Math/MathML",children:(0,i.jsxs)(s.semantics,{children:[(0,i.jsxs)(s.mrow,{children:[(0,i.jsx)(s.mi,{children:"w"}),(0,i.jsx)(s.mo,{children:"="}),(0,i.jsxs)(s.msup,{children:[(0,i.jsx)(s.mi,{children:"w"}),(0,i.jsx)(s.mo,{mathvariant:"normal",lspace:"0em",rspace:"0em",children:"\u2032"})]})]}),(0,i.jsx)(s.annotation,{encoding:"application/x-tex",children:"w = w'"})]})})}),(0,i.jsxs)(s.span,{className:"katex-html","aria-hidden":"true",children:[(0,i.jsxs)(s.span,{className:"base",children:[(0,i.jsx)(s.span,{className:"strut",style:{height:"0.4306em"}}),(0,i.jsx)(s.span,{className:"mord mathnormal",style:{marginRight:"0.02691em"},children:"w"}),(0,i.jsx)(s.span,{className:"mspace",style:{marginRight:"0.2778em"}}),(0,i.jsx)(s.span,{className:"mrel",children:"="}),(0,i.jsx)(s.span,{className:"mspace",style:{marginRight:"0.2778em"}})]}),(0,i.jsxs)(s.span,{className:"base",children:[(0,i.jsx)(s.span,{className:"strut",style:{height:"0.7519em"}}),(0,i.jsxs)(s.span,{className:"mord",children:[(0,i.jsx)(s.span,{className:"mord mathnormal",style:{marginRight:"0.02691em"},children:"w"}),(0,i.jsx)(s.span,{className:"msupsub",children:(0,i.jsx)(s.span,{className:"vlist-t",children:(0,i.jsx)(s.span,{className:"vlist-r",children:(0,i.jsx)(s.span,{className:"vlist",style:{height:"0.7519em"},children:(0,i.jsxs)(s.span,{style:{top:"-3.063em",marginRight:"0.05em"},children:[(0,i.jsx)(s.span,{className:"pstrut",style:{height:"2.7em"}}),(0,i.jsx)(s.span,{className:"sizing reset-size6 size3 mtight",children:(0,i.jsx)(s.span,{className:"mord mtight",children:(0,i.jsx)(s.span,{className:"mord mtight",children:"\u2032"})})})]})})})})})]})]})]})]})," and repeat the #1 until you reach the specific sequence length."]}),"\n"]}),"\n",(0,i.jsx)(s.p,{children:"Finally, the function returns a tuple comprising the following two elements:"}),"\n",(0,i.jsxs)(s.ul,{children:["\n",(0,i.jsx)(s.li,{children:"The list of tokens in the sequence"}),"\n",(0,i.jsxs)(s.li,{children:["The log-likelihood estimating the sequence probability using the bigram model. Use the logarithmic function to the base ",(0,i.jsxs)(s.span,{className:"katex",children:[(0,i.jsx)(s.span,{className:"katex-mathml",children:(0,i.jsx)(s.math,{xmlns:"http://www.w3.org/1998/Math/MathML",children:(0,i.jsxs)(s.semantics,{children:[(0,i.jsx)(s.mrow,{children:(0,i.jsx)(s.mi,{children:"e"})}),(0,i.jsx)(s.annotation,{encoding:"application/x-tex",children:"e"})]})})}),(0,i.jsx)(s.span,{className:"katex-html","aria-hidden":"true",children:(0,i.jsxs)(s.span,{className:"base",children:[(0,i.jsx)(s.span,{className:"strut",style:{height:"0.4306em"}}),(0,i.jsx)(s.span,{className:"mord mathnormal",children:"e"})]})})]}),", provided as the ",(0,i.jsx)(s.code,{children:"math.log()"})," function in Python."]}),"\n"]}),"\n",(0,i.jsx)(s.h3,{id:"extra-credit",children:"Extra Credit"}),"\n",(0,i.jsxs)(s.p,{children:["Create a function called ",(0,i.jsx)(s.code,{children:"sequence_generator_plus()"})," that takes the same input parameters as the existing ",(0,i.jsx)(s.code,{children:"sequence_generator()"})," function. This new function should generate sequences with higher probability scores and better semantic coherence compared to the original implementation."]}),"\n",(0,i.jsx)(s.h2,{id:"submission",children:"Submission"}),"\n",(0,i.jsxs)(s.p,{children:["Commit and push the ",(0,i.jsx)(s.strong,{children:"language_models.py"})," file to your GitHub repository."]}),"\n",(0,i.jsx)(s.h2,{id:"rubric",children:"Rubric"}),"\n",(0,i.jsxs)(s.ul,{children:["\n",(0,i.jsx)(s.li,{children:"Task 1: Bigram Modeling (5 points)"}),"\n",(0,i.jsx)(s.li,{children:"Task 2: Sequence Generator (4.6 points), Extra Credit (2 points)"}),"\n",(0,i.jsx)(s.li,{children:"Concept Quiz (2.4 points)"}),"\n"]})]})}function o(e={}){const{wrapper:s}={...(0,t.R)(),...e.components};return s?(0,i.jsx)(s,{...e,children:(0,i.jsx)(m,{...e})}):m(e)}},8453(e,s,a){a.d(s,{R:()=>l,x:()=>r});var n=a(6540);const i={},t=n.createContext(i);function l(e){const s=n.useContext(t);return n.useMemo(function(){return"function"==typeof e?e(s):{...s,...e}},[s,e])}function r(e){let s;return s=e.disableParentContext?"function"==typeof e.components?e.components(i):e.components||i:l(e.components),n.createElement(t.Provider,{value:s},e.children)}}}]);
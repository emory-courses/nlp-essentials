"use strict";(globalThis.webpackChunknlp_essentials_textbook=globalThis.webpackChunknlp_essentials_textbook||[]).push([[823],{9250(e){e.exports=JSON.parse('{"version":{"pluginId":"default","version":"current","label":"Next","banner":null,"badge":false,"noIndex":false,"className":"docs-version-current","isLast":true,"docsSidebars":{"chaptersSidebar":[{"type":"category","label":"Getting Started","items":[{"type":"link","href":"/nlp-essentials/getting_started/overview","label":"Overview","docId":"getting_started/overview","unlisted":false},{"type":"link","href":"/nlp-essentials/getting_started/syllabus","label":"Syllabus","docId":"getting_started/syllabus","unlisted":false},{"type":"link","href":"/nlp-essentials/getting_started/schedule","label":"Schedule","docId":"getting_started/schedule","unlisted":false},{"type":"link","href":"/nlp-essentials/getting_started/development-environment","label":"Development Environment","docId":"getting_started/development-environment","unlisted":false},{"type":"link","href":"/nlp-essentials/getting_started/homework","label":"Homework","docId":"getting_started/homework","unlisted":false}],"collapsed":true,"collapsible":true},{"type":"category","label":"Text Processing","items":[{"type":"link","href":"/nlp-essentials/text_processing/overview","label":"Overview","docId":"text_processing/overview","unlisted":false},{"type":"link","href":"/nlp-essentials/text_processing/frequency-analysis","label":"Frequency Analysis","docId":"text_processing/frequency-analysis","unlisted":false},{"type":"link","href":"/nlp-essentials/text_processing/tokenization","label":"Tokenization","docId":"text_processing/tokenization","unlisted":false},{"type":"link","href":"/nlp-essentials/text_processing/lemmatization","label":"Lemmatization","docId":"text_processing/lemmatization","unlisted":false},{"type":"link","href":"/nlp-essentials/text_processing/regular-expressions","label":"Regular Expressions","docId":"text_processing/regular-expressions","unlisted":false},{"type":"link","href":"/nlp-essentials/text_processing/homework","label":"Homework","docId":"text_processing/homework","unlisted":false}],"collapsed":true,"collapsible":true}]},"docs":{"getting_started/development-environment":{"id":"getting_started/development-environment","title":"Development Environment","description":"This guide will help you set up your development environment by installing required tools: Python programming language, GitHub for version control, and PyCharm IDE.","sidebar":"chaptersSidebar"},"getting_started/homework":{"id":"getting_started/homework","title":"Homework","description":"Task 1: Environmental Setup","sidebar":"chaptersSidebar"},"getting_started/overview":{"id":"getting_started/overview","title":"Overview","description":"This chapter introduces you to the course structure, learning objectives, and development environment setup. You will learn about course policies, grading criteria, and the tools you\'ll use throughout the semester. By the end of this chapter, you will have a fully configured development environment and be ready to start building natural language processing applications.","sidebar":"chaptersSidebar"},"getting_started/schedule":{"id":"getting_started/schedule","title":"Schedule","description":"CS|DATASCI|LING-329: Computational Linguistics (Spring 2026)","sidebar":"chaptersSidebar"},"getting_started/syllabus":{"id":"getting_started/syllabus","title":"Syllabus","description":"CS|DATASCI|LING-329: Computational Linguistics (Spring 2026)","sidebar":"chaptersSidebar"},"intro":{"id":"intro","title":"NLP Essentials","description":"By Jinho D. Choi (2026 Edition)"},"text_processing/frequency-analysis":{"id":"text_processing/frequency-analysis","title":"Frequency Analysis","description":"Frequency Analysis examines how often each word appears in a corpus. It helps understand language patterns and structure by measuring how often words appear in text.","sidebar":"chaptersSidebar"},"text_processing/homework":{"id":"text_processing/homework","title":"Homework","description":"HW1: Text Processing","sidebar":"chaptersSidebar"},"text_processing/lemmatization":{"id":"text_processing/lemmatization","title":"Lemmatization","description":"Sometimes, it is more appropriate to consider the canonical forms as tokens instead of their variations. For example, if you want to analyze the usage of the word \\"transformer\\" in NLP literature for each year, you want to count both \\"transformer\\" and \'transformers\' as a single item.","sidebar":"chaptersSidebar"},"text_processing/overview":{"id":"text_processing/overview","title":"Overview","description":"Text processing refers to the manipulation and analysis of textual data through techniques applied to raw text, making it more structured, understandable, and suitable for various applications.","sidebar":"chaptersSidebar"},"text_processing/regular-expressions":{"id":"text_processing/regular-expressions","title":"Regular Expressions","description":"Regular expressions, commonly abbreviated as regex, form a language for string matching, enabling operations to search, match, and manipulate text based on specific patterns or rules.","sidebar":"chaptersSidebar"},"text_processing/tokenization":{"id":"text_processing/tokenization","title":"Tokenization","description":"Tokenization is the process of breaking down a text into smaller units, typically words or subwords, known as tokens. Tokens serve as the basic building blocks used for a specific task.","sidebar":"chaptersSidebar"}}}}')}}]);